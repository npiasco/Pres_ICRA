\section{Learning through missing modality}

\label{sec:method}

\begin{frame}{System components}
	\begin{minipage}[t]{0.50\linewidth}
	\only<1>{
		\begin{figure}
		\centering		
		\includegraphics[width=\linewidth]{vect/method/fig2/0n}
		\end{figure}
		
		\vfill
		We use a CNN as trainable global image descriptor\footfullcite{Arandjelovic2017}.
		}
		\only<2->
		{
		\begin{figure}
		\centering
		\includegraphics[width=\linewidth]{vect/method/fig2/3n}
		\end{figure}	
		
		\vfill
		The deep image descriptor can be train with image triplet and triplet loss.
		}
	\end{minipage}\hfill
	\uncover<3>{
	\begin{minipage}[t]{0.49\linewidth}
		\begin{figure}	
			\centering
			\includegraphics[width=\linewidth]{vect/method/fig3/enc_dec}	
		\end{figure}
		
		\vfill		
		We trained a encoder-decoder to produce depth map according to monocular images.
	\end{minipage}
	}
\end{frame}

\begin{frame}{Our method: learning through missing modality}	
	\only<1>
	{
	\begin{minipage}{0.6\linewidth}
		\centering
		\includegraphics[width=\linewidth]{vect/method/fig3/1d}	
	\end{minipage}\hfill
	\begin{minipage}{0.3\linewidth}
		\raggedright
		We use triplet loss to produce strong image descriptor.
	\end{minipage}		
	}
	\only<2>
	{
	\begin{minipage}{0.6\linewidth}
		\centering
		\includegraphics[width=\linewidth]{vect/method/fig3/2d}	
	\end{minipage}\hfill
	\begin{minipage}{0.3\linewidth}
		\raggedright
		Latent image representation is given to a CNN decoder to reproduce the scene geometry.\\
		\vspace{0.5cm}
		
		The CNN decoder is simply trained by minimizing $L_{1}$ distance between ground truth and reconstructed depth.
	\end{minipage}		
	
	}
	\only<3>
	{
	\begin{minipage}{0.6\linewidth}
		\centering
		\includegraphics[width=\linewidth]{vect/method/fig3/3d}	
	\end{minipage}\hfill
	\begin{minipage}{0.3\linewidth}
		\raggedright
		We use another CNN to produce strong depth map descriptor.
	\end{minipage}			
	
	}
	\only<4>
	{
	\begin{minipage}{0.6\linewidth}
		\centering
		\includegraphics[width=\linewidth]{vect/method/fig3/4d}	
	\end{minipage}\hfill
	\begin{minipage}{0.3\linewidth}
		\raggedright
		Final descriptor is obtained by concatenating image and depth map descriptors.
	\end{minipage}			
	
	}
\end{frame}

\begin{frame}{Training policy}
	\only<1>
	{
	\begin{minipage}{0.6\linewidth}
		\centering
		\includegraphics[width=\linewidth]{vect/method/fig3/5d}	
	\end{minipage}\hfill
	\begin{minipage}{0.3\linewidth}
		\raggedright
		Data required to train the descriptor part of our system:
		\vspace{0.5cm}
		
		\includegraphics[width=\linewidth]{vect/method/fig3/triplet}	
	\end{minipage}		
	}
	\only<2>
	{
	\begin{minipage}{0.6\linewidth}
		\centering
		\includegraphics[width=\linewidth]{vect/method/fig3/6d}
	\end{minipage}\hfill
	\begin{minipage}{0.3\linewidth}
		\raggedright
		Data required to train the depth reconstruction part of our system:
		\vspace{0.5cm}
		
		\includegraphics[width=\linewidth]{vect/method/fig3/pair}	
	\end{minipage}			
	}
\end{frame}


\begin{frame}{System deployment}
	\centering
	\includegraphics[width=0.7\linewidth]{vect/method/fig4/final}
	\vfill	

	The depth information is only needed during the training step!
\end{frame}